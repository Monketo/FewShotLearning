{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_input = Input(shape=(105,105,1))\n",
    "\n",
    "x = Conv2D(64, (10, 10),activation='relu',input_shape=(105,105,1))(digit_input)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(128, (8, 8),activation='relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(128, (6, 6),activation='relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(256, (4, 4),activation='relu')(x)\n",
    "out = Flatten()(x)\n",
    "#out = Dense(4096,activation='sigmoid')(x)\n",
    "vision_model = Model(digit_input,out)\n",
    "\n",
    "letter1 = Input(shape=(105,105,1))\n",
    "letter2 = Input(shape=(105,105,1))\n",
    "\n",
    "out_1 = vision_model(letter1)\n",
    "out_2 = vision_model(letter2)\n",
    "\n",
    "def m_dist(A,B):\n",
    "    return K.sum(K.abs(A-B),axis=1,keepdims=True)\n",
    "\n",
    "merged_vector = Lambda(lambda x:m_dist(x[0],x[1]), output_shape=lambda inp_shp:(inp_shp[0][0],1))([out_1,out_2])\n",
    "\n",
    "out_fin = Dense(4096,activation=\"sigmoid\")(merged_vector)\n",
    "final_output = Dense(1,activation=\"sigmoid\")(out_fin)\n",
    "\n",
    "final_model = keras.models.Model(inputs=[letter1, letter2], outputs=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial \n",
    "def convolutional_mapper(my_input):\n",
    "    # Convolutional Layer #1\n",
    "        \n",
    "        conv_relu = parital(tf.layers.conv2d,actication=tf.nn.relu)\n",
    "        \n",
    "        conv1 = conv_relu(inputs=input_layer,filters=64,kernel_size=[10, 10],padding=\"same\")\n",
    "        \n",
    "        # Pooling Layer #1\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "        \n",
    "        # Convolutional Layer #2 and Pooling Layer #2\n",
    "        conv2 = conv_relu(inputs=pool1,filters=128,kernel_size=[8, 8],padding=\"same\")\n",
    "\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        conv3 = tf.layers.conv2d(inputs=pool2,filters=128,kernel_size=[6, 6],padding=\"same\",activation=tf.nn.relu)\n",
    "\n",
    "        pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        conv4 = tf.layers.conv2d(inputs=pool2,filters=128,kernel_size=[6, 6],padding=\"same\",activation=tf.nn.relu)\n",
    "\n",
    "        # Dense Layer\n",
    "        pool5_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "        \n",
    "        return pool5_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_manhattan_distance(x, y):\n",
    "    \n",
    "    size_x = x.shape.dims[0]\n",
    "    size_y = y.shape.dims[0]\n",
    "    for i in range(size_x):\n",
    "        tile_one = tf.reshape(tf.tile(x[i], [size_y]), [size_y, -1])\n",
    "        eu_one = tf.expand_dims(tf.reduce_sum(tf.abs(tf.subtract(tile_one, y)), axis=1), axis=0)\n",
    "        if i == 0:\n",
    "            d = eu_one\n",
    "        else:\n",
    "            d = tf.concat([d, eu_one], axis=0)\n",
    "            \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-11-9f5b8bfb8595>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-9f5b8bfb8595>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    \n",
    "    # Input Layer\n",
    "    \n",
    "    input_layer1 = tf.reshape(features[\"image1\"], [-1, 105, 105, 1])\n",
    "    input_layer2 = tf.reshape(features[\"image2\"], [-1, 105, 105, 1])\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(\"mapped_image1\"):\n",
    "        mapped1 = convolutional_mapper(input_layer1)\n",
    "        \n",
    "    with tf.variable_scope(\"mapped_image2\",reuse=True):\n",
    "        mapped2 = convolutional_mapper(input_layer2)\n",
    "        \n",
    "    component_wise_distance = compute_manhattan_distance(mapped1,mapped2)\n",
    "    \n",
    "    dense_final = tf.layers.dense(inputs=component_wise_distance, units=4096, activation=tf.nn.sigmoid)\n",
    "   \n",
    "    logits = tf.layers.dense(inputs=dense_final, units=1)\n",
    "    \n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.sigmoid(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.binary_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
